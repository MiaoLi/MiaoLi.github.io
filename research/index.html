<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Research | Dr. Miao Li</title>
  <meta name="description" content="TODO
">

  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="http://localhost:4000/research/">
  <link rel="alternate" type="application/rss+xml" title="Dr. Miao Li" href="http://localhost:4000/feed.xml" />
<link rel='stylesheet' id='open-sans-css'  href='//fonts.googleapis.com/css?family=Open+Sans%3A300italic%2C400italic%2C600italic%2C300%2C400%2C600&#038;subset=latin%2Clatin-ext&#038;ver=4.2.4' type='text/css' media='all' />
<link href='http://fonts.googleapis.com/css?family=Titillium+Web:600italic,600,400,400italic' rel='stylesheet' type='text/css'>
<link rel="stylesheet" href="https://www.osu.edu/assets/fonts/webfonts.css">
<link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css">




</head>


  <body>

    <header class="site-header">

  <div class="wrapper">

    <a class="site-title" href="/">Dr. Miao Li</a>


    <nav class="site-nav">

      <a href="#" class="menu-icon menu.open">
        <svg viewBox="0 0 18 15">
          <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
      </a>  

    <div class="trigger"><h1>Main Navigation</h1>

 <ul class="menu">

    
    
     <li><a href="/research/" class="page-link">Research</a>
    
    </li>
    
    
     <li><a href="/publications/" class="page-link">Publications</a>
    
    </li>
    
    
     <li><a href="/applications/" class="page-link">Applications</a>
    
    </li>
    
    </ul>


<!-- <ul class="menu">
        <li> <a class="page-link" href="/about">About</a></li>
        <li> <a class="page-link"  href="/blog">Blog</a>
        <li> <a class="page-link" href="/blog">CV</a>
        <li> <a class="page-link" href="/blog">For Students</a></li>
        <li> <a class="page-link"  href="/blog">Research</a></a>
        <li> <a class="page-link" href="/blog">Teaching</a>
<ul class="sub-menu">
	<li><a href="http://svmiller.com/teaching/posc-1020-introduction-to-international-relations/">POSC 1020 – Introduction to International Relations</a></li>
	<li><a href="http://svmiller.com/teaching/posc-3410-quantitative-methods-in-political-science/">POSC 3410 – Quantitative Methods in Political Science</a></li>
	<li><a href="http://svmiller.com/teaching/posc-3610-international-politics-in-crisis/">POSC 3610 – International Politics in Crisis</a></li>
	<li><a href="http://svmiller.com/teaching/posc-3630-united-states-foreign-policy/">POSC 3630 – United States Foreign Policy</a></li>
</ul></li>
        <li> <a class="page-link" href="/blog">Miscellany</a>
<ul class="sub-menu">
	<li><a href="http://svmiller.com/teaching/posc-1020-introduction-to-international-relations/">Clean USAID Greenbook Data</a></li>
	<li><a href="http://svmiller.com/teaching/posc-3410-quantitative-methods-in-political-science/">Journal of Peace Research *.bst File</a></li>
	<li><a href="http://svmiller.com/teaching/posc-3610-international-politics-in-crisis/">My Custom Beamer Style</a></li>
</ul> 

</li>
</ul> -->

     </div>  
    </nav>

  </div>

</header>


    <div class="page-content">
      <div class="wrapper">
        <div class="post">

  <header class="post-header">
    <h1 class="post-title">Research</h1>
  </header>

  <article class="post-content">
  <p>My research is focused towards building intelligent robot systems that can make decisions under uncertainty in dynamic and human-centered environments. I view this problem as a question of searching suitable task  representations for optimal computational reasoning, including designing, planning, control and learning. As a demonstrator platform, I am extremely interested in robotic grasping, since the human hand is an amazing tool demonstrated by its incredible motor capability and remarkable sense of touch.</p>

<h2 id="grasp-planning"><strong>Grasp Planning</strong></h2>

<p> Choosing an optimal grasp for a given object is one of the core problems in robotic grasping. The optimality is constrained by the hand kinematics, task at hand and the object properties (shape, dynamics, friction, etc.). In this research, we study how the hand kinematics, object shape and task requirements influence the grasp planning process. This part includes traditional model-based planning as well as learning-based approaches.</p>

<h3 id="one-shot-grasp-planning">One Shot Grasp Planning</h3>

<div class="pull-left" style="width: 250px; margin-right: 20px;">
  <!-- <p><img src="/images/icub-grasp.PNG" alt="Visualization of icub grasping." /></p> -->
  <p><img src="/images/icub-grasp-2.PNG" alt="Visualization of icub grasping." /></p>
</div>

<p>Optimal grasp synthesis has traditionally been solved in two steps: determining optimal grasping points according
to a specific quality criterion and then determining how to shape the hand to produce these grasping points. Generating optimal grasps depends on the position of contact points as much as the configuration of the robot hand and it would hence be desirable to solve this in a single step. This research takes advantage of new development in non-linear optimization and formulates the problem of grasp synthesis as a single constrained optimization problem, generating grasps that are at the same time feasible for the hand’s kinematics and optimal according to a force related quality measure.</p>

<h3 id="dexterous-grasping-under-shape-uncertainty">Dexterous Grasping under Shape Uncertainty</h3>

<div class="pull-right" style="width: 350px; margin-right: 20px;">
  <p><img src="/images/shape-grasp.PNG" alt="Visualization of grasp planning under shape uncertainty." /></p>
</div>

<p>An important challenge in robotics is to achieve robust performance in object grasping and manipulation,
dealing with noise and uncertainty. This research presents an approach for addressing the performance
of dexterous grasping under shape uncertainty. In our approach, the uncertainty in object shape is
parametrized and incorporated as a constraint into grasp planning. The proposed approach is used to plan
feasible hand configurations for realizing planned contacts using different robotic hands (Barrett Hand, Allegro Hand).</p>

<p><br /></p>

<h3 id="grasp-with-task-specific-contact">Grasp with Task-specific Contact</h3>

<div class="pull-left" style="width: 250px; margin-right: 20px;">
  <p><img src="/images/task-grasp.PNG" alt="Visualization of grasp planning under task requirements." /></p>
</div>

<p>Generating robotic grasps for given tasks is a difficult problem. This research proposes a learning-based approach
to generate suitable partial power grasp for a set of tool-using tasks. First a number of valid partial power grasps
are sampled in simulation and encoded as a probabilistic model, which encapsulates the relations among the task-specific contact, the graspable object feature and the finger joints. With the
learned model, suitable grasps can be generated on-line given the task-specific contact. Moreover, a grasp adaptation strategy is proposed to locally adjust the specified contact in order to increase the grasp feasibility and also the quality of the final found grasp. We demonstrate the effectiveness of our approach
using a 16 DOF robotic hand – Allegro Hand, on a variety of tool-using tasks</p>
<p><br /></p>

<h2 id="grasp-adaptation"><strong>Grasp Adaptation</strong></h2>

<p>For a long time, the robotic grasping community focuses too much on the grasp planning part. However, for real world applications, it is important to know whether the planned grasp is stable or not. In this research, we study how to predict the stability of a given grasp with trained grasping experience from the perspective of the grasped object. With the learned stability estimator, if a grasp is predicted as unstable, we devise an adaptation strategy to stabilize the given grasp. Moreover, to close the loop between initial planning and the adaptation process, we design a closed-loop adaptation strategy to stabilize the grasp in real-time while keep the hand grasp capability in mind.
</p>

<h3 id="learning-grasp-stability">Learning Object-level Impedance Control</h3>
<div class="pull-right" style="width: 300px; margin-right: 20px;">
  <p><img src="/images/object-level-impedance.PNG" alt="Visualization of learning object-level impedance." /></p>
</div>

<p>Object-level impedance control is of great importance
for object-centric tasks, such as robust grasping and
dexterous manipulation. Despite the recent progresses on this
topic, how to specify the desired object impedance for a given
task remains an open issue. In this work, we decompose
the object’s impedance into two complementary components–
the impedance for stable grasping and impedance for object
manipulation. Then, we present a method to learn the desired
object’s manipulation impedance (stiffness) using data obtained
from human demonstration. The approach is validated in two
tasks, for robust grasping of a wine glass and for inserting a
bulb, using the 16 degrees of freedom Allegro Hand mounted
with the SynTouch tactile sensors.</p>

<h3 id="learning-grasp-stability">Learning Grasp Stability</h3>

<div class="pull-left" style="width: 250px; margin-right: 20px;">
  <p><img src="/images/grasp-stability.PNG" alt="Visualization of learning grasp stability." /></p>
</div>

<p>To perform robust grasping, a multi-fingered robotic hand should be able to adapt its grasping configuration,
i.e., how the object is grasped, to maintain the stability of the grasp. Such a change of grasp configuration is called grasp adaptation and it depends on the controller, the employed sensory feedback and the type of uncertainties inherit to the problem. This paper proposes a grasp adaptation strategy to deal with uncertainties about physical properties of objects, such as the object weight and the friction at the contact points. Based on an object-level impedance controller, a grasp stability estimator is first learned in the object frame. Once a grasp is
predicted to be unstable by the stability estimator, a grasp adaptation strategy is triggered according to the similarity between the new grasp and the training examples. Experimental results demonstrate that our method improves the grasping performance on novel objects with different physical properties from those used for training</p>

<p><br /></p>

<h3 id="dynamic-grasp-adaptation">Dynamic Grasp Adaptation</h3>

<div class="pull-right" style="width: 200px; margin-right: 20px;">
  <p><img src="/images/grasp-adaptation.jpg" alt="Visualization of dynamic grasp adaptation." /></p>
</div>

<p>We present a unified framework for grasp planning
and in-hand grasp adaptation using visual, tactile, and
proprioceptive feedback. The main objective of the proposed
framework is to enable fingertip grasping by addressing problems
of changed weight of the object, slippage, and external disturbances.
For this purpose we introduce the Hierarchical Fingertip
Space as a representation enabling optimization for both efficient
grasp synthesis and online finger gaiting. Grasp synthesis is followed
by a grasp adaptation step that consists of both grasp force
adaptation through impedance control and regrasping/finger gaiting
when the former is not sufficient. Experimental evaluation is
conducted on an Allegro hand mounted on a Kuka LWR arm.</p>

<p><br /></p>

<h2 id="compliant-manipulation"><strong>Compliant Manipulation</strong></h2>

<p>Object manipulation is a challenging task for robotics, as the physics involved in object interaction is complex
and hard to express analytically. Extended from the robotic grasping research, in this research we study the underlying interaction model between the object and the environment. To enable
robust physical interaction with the environment, different models have been investigated to represent the task at hand, including modular approach, manifold learning, etc. To facilitate the model learning process, we adopt the learning from demonstration framework where the data collected from demonstration are used from model training. </p>

<h3 id="modular-approach"> Learning Manipulation Strategies from Human Demonstration</h3>

<div class="pull-left" style="width: 250px; margin-right: 20px;">
  <p><img src="/images/modular-approach.PNG" alt="Visualization of people tracking." /></p>
</div>

<p>Here we introduce a modular approach for learning a manipulation strategy from
human demonstration. Firstly we record a human performing a task that requires an adaptive control strategy in different conditions, i.e. different task contexts.We then perform modular decomposition of the control strategy, using phases of the recorded actions to guide segmentation. Each module represents a part of the strategy, encoded as a pair of forward and inverse models. All modules contribute to the final control policy; their recommendations are integrated via a system of weighting based on their own estimated error in the current task context.We validate our approach by demonstrating it, both in a simulation for clarity, and on a real robot platform to demonstrate robustness and capacity to generalise. The robot task is opening bottle caps. We show that our approach can modularize an adaptive control strategy and generate appropriate motor commands for the robot to accomplish the complete task, even for novel bottles</p>


  </article>

</div>

      </div>
    </div>

<footer class="site-footer">

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col  footer-col-1">
        <ul class="contact-list">
          <li><strong style="font-weight: 500;">Dr. Miao Li</strong></li>
          <li>Robots for real life</li>
          <li><a href="mailto:limiao712@gmail.com">limiao712@gmail.com</a></li>
        </ul>
      </div>

      <div class="footer-col  footer-col-2">
        <ul class="social-media-list">
     


  <li>
    <a href="https://scholar.google.com/citations?user=hPQY4voAAAAJ&hl=en">
      <i class="fa fa-google" style="color:gray"></i> google scholar
    </a>
  </li>



  <li>
    <a href="https://github.com/MiaoLi">
      <i class="fa fa-github" style="color:gray"></i> MiaoLi
    </a>
  </li>
       
      </ul>
      </div>

      <div class="footer-col  footer-col-3">
         <p class="text">
    Learning Algorithms for Soft Manipulation (LASM)<br />
    School of Power and Mechanical Engineering<br />
    Wuhan University<br/>
    Wuhan, Hubei, China, 430074</p> 
      </div>
    </div>

  </div>

</footer>

		<script type="text/javascript">
	var _gaq = _gaq || [];
	_gaq.push(['_setAccount', 'UA-37298398-1']);
	_gaq.push(['_trackPageview']);
	(function() {
	var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
	ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
	var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
	})();
	</script>
  </body>
</html>
<!-- d.050600.062508.030515.080516 | "Baby, I'm Yours" -->

