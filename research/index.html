<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Research | Dr. Miao Li</title>
  <meta name="description" content="TODO
">

  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="http://localhost:4000/research/">
  <link rel="alternate" type="application/rss+xml" title="Dr. Miao Li" href="http://localhost:4000/feed.xml" />
<link rel='stylesheet' id='open-sans-css'  href='//fonts.googleapis.com/css?family=Open+Sans%3A300italic%2C400italic%2C600italic%2C300%2C400%2C600&#038;subset=latin%2Clatin-ext&#038;ver=4.2.4' type='text/css' media='all' />
<link href='http://fonts.googleapis.com/css?family=Titillium+Web:600italic,600,400,400italic' rel='stylesheet' type='text/css'>
<link rel="stylesheet" href="https://www.osu.edu/assets/fonts/webfonts.css">
<link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css">




</head>


  <body>

    <header class="site-header">

  <div class="wrapper">

    <a class="site-title" href="/">Dr. Miao Li</a>


    <nav class="site-nav">

      <a href="#" class="menu-icon menu.open">
        <svg viewBox="0 0 18 15">
          <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
      </a>  

    <div class="trigger"><h1>Main Navigation</h1>

 <ul class="menu">

    
    
     <li><a href="/research/" class="page-link">Research</a>
    
    </li>
    
    
     <li><a href="/publications/" class="page-link">Publications</a>
    
    </li>
    
    
     <li><a href="/applications/" class="page-link">Applications</a>
    
    </li>
    
    </ul>


<!-- <ul class="menu">
        <li> <a class="page-link" href="/about">About</a></li>
        <li> <a class="page-link"  href="/blog">Blog</a>
        <li> <a class="page-link" href="/blog">CV</a>
        <li> <a class="page-link" href="/blog">For Students</a></li>
        <li> <a class="page-link"  href="/blog">Research</a></a>
        <li> <a class="page-link" href="/blog">Teaching</a>
<ul class="sub-menu">
	<li><a href="http://svmiller.com/teaching/posc-1020-introduction-to-international-relations/">POSC 1020 – Introduction to International Relations</a></li>
	<li><a href="http://svmiller.com/teaching/posc-3410-quantitative-methods-in-political-science/">POSC 3410 – Quantitative Methods in Political Science</a></li>
	<li><a href="http://svmiller.com/teaching/posc-3610-international-politics-in-crisis/">POSC 3610 – International Politics in Crisis</a></li>
	<li><a href="http://svmiller.com/teaching/posc-3630-united-states-foreign-policy/">POSC 3630 – United States Foreign Policy</a></li>
</ul></li>
        <li> <a class="page-link" href="/blog">Miscellany</a>
<ul class="sub-menu">
	<li><a href="http://svmiller.com/teaching/posc-1020-introduction-to-international-relations/">Clean USAID Greenbook Data</a></li>
	<li><a href="http://svmiller.com/teaching/posc-3410-quantitative-methods-in-political-science/">Journal of Peace Research *.bst File</a></li>
	<li><a href="http://svmiller.com/teaching/posc-3610-international-politics-in-crisis/">My Custom Beamer Style</a></li>
</ul> 

</li>
</ul> -->

     </div>  
    </nav>

  </div>

</header>


    <div class="page-content">
      <div class="wrapper">
        <div class="post">

  <header class="post-header">
    <h1 class="post-title">Research</h1>
  </header>

  <article class="post-content">
  <p>My research is focused towards building intelligent robot systems that can make decisions under uncertainty in dynamic and human-centered environments. I view this problem as a question of searching suitable task  representations for optimal computational reasoning, including designing, planning, control and learning. As a demonstrator platform, I am extremely interested in robotic grasping, since the human hand is an amazing tool demonstrated by its incredible motor capability and remarkable sense of touch.</p>

<h2 id="grasp-planning">Grasp Planning</h2>

<p> Choosing an optimal grasp for a given object is one of the core problems in robotic grasping. The optimality is constrained by the hand kinematics, task at hand and the object properties (shape, dynamics, friction, etc.). In this research, we study how the hand kinematics, object shape and task requirements influence the grasp planning process. This part includes traditional model-based planning as well as learning-based approaches.</p>

<h3 id="one-shot-grasp-planning">One Shot Grasp Planning</h3>

<div class="pull-left" style="width: 250px; margin-right: 20px;">
  <!-- <p><img src="/images/icub-grasp.PNG" alt="Visualization of icub grasping." /></p> -->
  <p><img src="/images/icub-grasp-2.PNG" alt="Visualization of icub grasping." /></p>
</div>

<p>Optimal grasp synthesis has traditionally been solved in two steps: determining optimal grasping points according
to a specific quality criterion and then determining how to shape the hand to produce these grasping points. Generating optimal grasps depends on the position of contact points as much as the configuration of the robot hand and it would hence be desirable to solve this in a single step. This research takes advantage of new development in non-linear optimization and formulates the problem of grasp synthesis as a single constrained optimization problem, generating grasps that are at the same time feasible for the hand’s kinematics and optimal according to a force related quality measure.</p>

<h3 id="dexterous-grasping-under-shape-uncertainty">Dexterous Grasping under Shape Uncertainty</h3>

<div class="pull-left" style="width: 300px; margin-right: 20px;">
  <p><img src="/images/shape-grasp.PNG" alt="Visualization of grasp planning under shape uncertainty." /></p>
</div>

<p>An important challenge in robotics is to achieve robust performance in object grasping and manipulation,
dealing with noise and uncertainty. This research presents an approach for addressing the performance
of dexterous grasping under shape uncertainty. In our approach, the uncertainty in object shape is
parametrized and incorporated as a constraint into grasp planning. The proposed approach is used to plan
feasible hand configurations for realizing planned contacts using different robotic hands (Barrett Hand, Allegro Hand).</p>

<p><br /></p>

<h3 id="socially-normative-navigation">Socially Normative Navigation</h3>

<div class="pull-left" style="width: 250px; margin-right: 20px;">
  <p><img src="/images/irl.png" alt="Visualization of people tracking." /></p>
</div>

<p>A robot that operates in a human-populated environment best behaves in an expectable and familiar way when navigating. In my research, I therefore used learning from demonstration to imitate human navigation behavior in encounter and crowd situations. The method learns a distribution over behaviors and at the same time provides a cost function for motion planning.</p>

<p><br /></p>
<h3 id="audio-based-activity-recognition">Audio-based Activity Recognition</h3>

<div class="pull-left" style="width: 250px; margin-right: 20px;">
  <p><img src="/images/stork2011audio.jpg" alt="Visualization of people tracking." /></p>
</div>

<p>Activites of humans create characteristic sounds, however there are often no strict temporal boundaries between activities and many other sources of sound in a populated environment. In my research, I used a non-parametric, non-Markovian approach with a committee of experts for recoginizing activities.</p>

<p>This research also resulted in a benchmark dataset.</p>

<p><br /></p>

<h3 id="scene-understanding">Scene Understanding</h3>

<p>Our environments a not only built for humans, they are also structured by us. This means that we arrange objects in our spaces according to our needs and habbits. From the perspective of an artificial agent that has to understand our environment, to e.g. find and object, this provides additional structure. However, perception in cluttered environments such as a kitchen or an office is difficult. In our research, we therefore assumed that only rough geometric information, such as position and general size, of objects are available. The method therefore reasons based on the spacial relationships between the objects about their class.</p>

<h2 id="grasp-adaptation">Grasp Adaptation</h2>

<p>For a long time, the major challenge for robotics was navigation and thereby necessarily localization and mapping. To perform a task, however, a robot often needs to interact with physical objects in the environment with close contact. This is required for lifting, transporting, and using objects as tools. Consequently, desiging grasps, that is identifying the parameters of the manipulator (hand) relative to the object with respect to objectives, is now a fundamental challenge in robotics. Here, both object shape and degrees of freedom of the manipulator intorduce complex spaces for decision making.</p>

<h3 id="fingertip-graps">Fingertip Graps</h3>

<div class="pull-left" style="width: 250px; margin-right: 20px;">
  <p><img src="/images/hang2014combinatorial.jpg" alt="Visualization of people tracking." /></p>
</div>

<p>Often, we only hold objects with our fingertips. This is a type of grasp that allows us to manipulate the object and is often associated with precision in interaction. For desiging a fingertip grasp, we have to analyze the object’s shape and understand the hand’s abilities since a grasp can only exist where the geometry of object and hand meet. What is challenging in fingertip grasp design is the large and complex search space of grasps on an object and the complex relationship to the hand’s kinematic. Additonally, grasp objectives such as mechanical stability are difficult to decompose into decoupled problems and therefore make it difficult to operate on partial solutions as is often the case in optimization.</p>

<div class="pull-right" style="width: 200px; margin-right: 20px;">
  <p><img src="/images/hang2017framework.png" alt="Visualization of people tracking." /></p>
</div>

<p>In our research, we turn to abstraction and optimization to design fingertip grasps and iteratively improve solutions on more exact representations of the same problem. For this, we introduced the object’s fingertip space hierarchy  which describes all positions where a fingertip can be placed and their similarity in several levels of abstraction. We also reduced optimal fingertip grasping to path-finding which allows for efficient and heuristic algorithms for optimal grasping.</p>

<p><br /></p>

<h3 id="catenane-caging">Catenane Caging</h3>

<div class="pull-left" style="width: 250px; margin-right: 20px;">
  <p><img src="/images/caging.png" alt="Visualization of people tracking." /></p>
</div>

<p>Another way to move or manipulate an object is caging. A caged object is not ridgitly fixated but instead merely constraint in its motion such that it cannot escape. This has the advantage that the interaction between object and manipulator is felxible and that the object’s small-scale geometry is less relevant to caging compared to grasp design. However, caging is difficult because of its general and essentially geometric nature. Reasoning about the spacial relationship of two bodies in geometric terms is computationally hard. In my research, I therefore used topoligical representation of object and hand allowing direct analysis of the caging property. The representation is based on holes and allows to model a type of caging as inter-linking object and hand like links of a chain.</p>

<p><br /></p>

<h2 id="compliant-manipulation">Compliant Manipulation</h2>

<div class="pull-left" style="width: 250px; margin-right: 20px;">
  <p><img src="/images/stork2015semantically.jpg" alt="" /></p>
</div>

<p>For an intelligent agent to be autonomous, it needs the capacity to adapt to its environment by learning the environemnt’s properties. This entails understanding the consequences of its actions in the environment. In realistic settings, the environment’s state cannot be directly observed, it is latent, transitions are stochastic, and observations are perturbed by other signals and imperfect sensors. Predictive State Representations (PSRs) are a class of models that were designed to learn representations of such environments. They do not depend on a nominal state space and assign no semantics to the learned state vector. However, learning them in realistic scenarios is hard and guarantees only hold under ideal conditions for discrete systems.</p>

<p>In my research, I explored the use of PSRs in continuous robotic systems to control a robot with Reinforcement Learning. I focused on the feature space embedding which determines the shape of the PSR’s state space. Under the condition of sparse data this embedding as a major effect on the model’s quality and performance. I used embeddings based on sequence kernels and learned embeddings based on robotic priors.</p>

<h3 id="in-hand-manpulation-and-external-dextarity">In-Hand Manpulation and External Dextarity</h3>

<div class="pull-left" style="width: 250px; margin-right: 20px;">
  <p><img src="/images/stork2015learning-A.jpg" alt="Visualization of people tracking." /></p>
</div>

<p>In-hand manipulation is an important ability for humans. Almost all objects we pick up we later re-orient and re-position to use them, e.g. a pencil. At the same time, we often use external ressources when interacting with objects we hold in our hands. One example is pushing an object against a contact in the environment. To a simple manipulator this provides a range interactions that otherwise would only be accessible to a hand with many fingers and joints, called external dexterity.</p>

<p>In my research, I modeled an in-hand manipulation scenario with external dexterity as a PSR and learned a representation of the system only based on tactile feedback from pressure sensors in the hand’s fingertips. This system is challenging to learn and model because many different states result in similar observations (aliasing) and the tedious procedure for data collection inhibits large sets of traning examples.</p>


  </article>

</div>

      </div>
    </div>

<footer class="site-footer">

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col  footer-col-1">
        <ul class="contact-list">
          <li><strong style="font-weight: 500;">Dr. Miao Li</strong></li>
          <li>Robots for real life</li>
          <li><a href="mailto:limiao712@gmail.com">limiao712@gmail.com</a></li>
        </ul>
      </div>

      <div class="footer-col  footer-col-2">
        <ul class="social-media-list">
     


  <li>
    <a href="https://scholar.google.com/citations?user=hPQY4voAAAAJ&hl=en">
      <i class="fa fa-google" style="color:gray"></i> google scholar
    </a>
  </li>



  <li>
    <a href="https://github.com/MiaoLi">
      <i class="fa fa-github" style="color:gray"></i> MiaoLi
    </a>
  </li>
       
      </ul>
      </div>

      <div class="footer-col  footer-col-3">
         <p class="text">
    Learning Algorithms for Soft Manipulation (LASM)<br />
    School of Power and Mechanical Engineering<br />
    Wuhan University<br/>
    Wuhan, Hubei, China, 430074</p> 
      </div>
    </div>

  </div>

</footer>

		<script type="text/javascript">
	var _gaq = _gaq || [];
	_gaq.push(['_setAccount', 'UA-37298398-1']);
	_gaq.push(['_trackPageview']);
	(function() {
	var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
	ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
	var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
	})();
	</script>
  </body>
</html>
<!-- d.050600.062508.030515.080516 | "Baby, I'm Yours" -->

